package writer

import (
	"fmt"
	"io"
	"strings"
	"time"
)

// SQLWriter implements Writer for SQL dumps.
type SQLWriter struct {
	w io.Writer
}

func NewSQLWriter(w io.Writer) *SQLWriter {
	return &SQLWriter{w: w}
}

func (sw *SQLWriter) WriteHeader(dbType string) error {
	timestamp := time.Now().Format(time.RFC3339)
	_, err := fmt.Fprintf(sw.w, "-- %s dump (Generated by Go)\n-- Generated on: %s\n--\n\n", dbType, timestamp)
	return err
}

func (sw *SQLWriter) WriteSchema(table, schema string) error {
	_, err := fmt.Fprintf(sw.w, "\n-- Schema for table: %s\n%s\n\n", table, schema)
	return err
}

func (sw *SQLWriter) WriteData(table string, data []string) error {
	prefix := fmt.Sprintf("INSERT INTO %s VALUES ", table)
	for _, batch := range chunkSlice(data, 1000) {
		_, err := fmt.Fprintf(sw.w, "%s(%s);\n", prefix, strings.Join(batch, ", "))
		if err != nil {
			return err
		}
	}
	return nil
}

func (sw *SQLWriter) Flush() error { return nil }

// chunkSlice utility for sub-batching.
func chunkSlice[T any](slice []T, size int) [][]T {
	var chunks [][]T
	if size <= 0 {
		return chunks // Avoid panic or infinite loop
	}
	for i := 0; i < len(slice); i += size {
		end := i + size
		if end > len(slice) {
			end = len(slice)
		}
		chunks = append(chunks, slice[i:end])
	}
	return chunks
}
